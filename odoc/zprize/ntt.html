<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>ntt (zprize.ntt)</title><link rel="stylesheet" href="../odoc.css"/><meta charset="utf-8"/><meta name="generator" content="odoc 2.1.1"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body class="odoc"><nav class="odoc-nav"><a href="index.html">Up</a> â€“ <a href="index.html">zprize</a> &#x00BB; ntt</nav><header class="odoc-preamble"><h2 id="hardcaml_ntt"><a href="#hardcaml_ntt" class="anchor"></a>Hardcaml_ntt</h2><p>This is a document about the design of a single NTT-evaluation block</p><p>The rough overview of the design is as follows:</p> <img src="https://fyquah.github.io/hardcaml_zprize/assets/ntt-core-overview.png" /><p>This designed core is designed with throughput in mind:</p><ul><li>the input-ram and output-ram can be read from and written to while the controller is doing work</li><li>the controller tries to give work to the datapath every clock cycle to ensure that the datapath stays busy</li></ul><p>Not depicited in the diagram is some resource sharing. In practice, it is wasteful to have a single controller for every datapath, transposer ram etc. In our implementation, we have a controller manage 8 cores, as a balance between fan-out and resource savings.</p></header><nav class="odoc-toc"><ul><li><a href="#data-path">Data path</a></li><li><a href="#controller">Controller</a></li><li><a href="#rams">RAMs</a></li><li><a href="#scaling">Scaling</a></li><li><a href="#api-documentation">API Documentation</a></li></ul></nav><div class="odoc-content"><h3 id="data-path"><a href="#data-path" class="anchor"></a>Data path</h3><p>The data path consists of 2 field multipliers and adders.</p><p>The multipliers are used in the transform phase to process one full butterfly operation per cycle. This consists of scaling the input coefficient and also the root of unity. Thus the performance of this architecture is <code>N/2 * log N</code>.</p><p>The data path is reused to perform the twiddle phase after the first pass of the 4-step algorithm. Each coefficient must be scaled by a specific root of unity and then the root scaled. This pass take N cycles.</p><h3 id="controller"><a href="#controller" class="anchor"></a>Controller</h3><p>The controller sequences the address for coefficient RAMs and the controls the data path.</p><h3 id="rams"><a href="#rams" class="anchor"></a>RAMs</h3><p>We required 2 read and 2 write ports for all RAMs in the design. This includes the inputs RAMs, internal RAMs, and output RAMs.</p><p>Since FPGA RAMs consist of 2 ports, we build our require structure from 2 UltraRAMs. Each UltraRAM has both it's ports connected to either the read or write side.</p><p>When a <code>flip</code> signal is toggled the port directions swap.</p><p>The RAMs are architectued such that we can load new INNT coefficents, store a processed INTT, and perform a INNT in parallel.</p><h3 id="scaling"><a href="#scaling" class="anchor"></a>Scaling</h3><p>Our design can be parameterized by <code>logcores</code> and <code>logblocks</code>.</p><p>The <code>Parallel_cores</code> block instantiates <code>1 &lt;&lt; logcores</code> INTT blocks. It also defines the width of the data path into the cores.</p><p>The <code>Multi_parallel_cores</code> block instantiates <code>1 &lt;&lt; logblocks</code> <code>Parallel_cores</code> blocks. This the design scales with <code>1 &lt;&lt; (logcores + logblocks)</code> cores.</p><h3 id="api-documentation"><a href="#api-documentation" class="anchor"></a>API Documentation</h3><p><a href="Hardcaml_ntt/index.html">Documentation</a></p></div></body></html>